"""To produce consistent results we adopt the following pipeline:

**Step 1:** Evaluate model on a test dataset and write out all data of interest:

    - generated image
    - latent representations

**Step 2:** Load the generated data in a Datafolder using the EvalDataset

**Step 3:** Pass both the test Dataset and the Datafolder to the evaluation scripts

Sometime in the future:
**(Step 4):** Generate a report:

    - latex tables
    - paths to videos
    - plots

Usage
-----

The pipeline is easily setup: In you Iterator (Trainer or Evaluator) add
the EvalHook and as many callbacks as you like. You can also pass no callback
at all.

.. warning::

    To use the output with ``edeval`` you must set ``config=config``.

.. code-block:: python

    from edflow.eval.pipeline import EvalHook

    def my_callback(root, data_in, data_out, config):
        # Do somethin fancy with the data
        results = ...

        return results

    class MyIterator(PyHookedModelIterator):
        """ """
        def __init__(self, config, root, model, **kwargs):

            self.model = model

            self.hooks += [EvalHook(self.dataset,
                                    callbacks={'cool_cb': my_callback},
                                    config=config,  # Must be specified for edeval
                                    step_getter=self.get_global_step)]

        def eval_op(self, inputs):
            return {'generated': self.model(inputs)}

        self.step_ops(self):
            return self.eval_op


Next you run your evaluation on your data using your favourite edflow command.

.. code-block:: bash

    edflow -n myexperiment -e the_config.yaml -p path_to_project

This will create a new evaluation folder inside your project's eval directory.
Inside this folder everything returned by your step ops is stored. In the case
above this would mean your outputs would be stored as
``generated:index.something``. But you don't need to concern yourself with
that, as the outputs can now be loaded using the :class:`EvalDataFolder`.

All you need to do is pass the EvalDataFolder the root folder in which the data
has been saved, which is the folder where you can find the
``model_outputs.csv``. Now you have all the generated data easily usable at
hand. The indices of the data in the EvalDataFolder correspond to the indices
of the data in the dataset, which was used to create the model outputs. So
you can directly compare inputs, targets etc, with the outputs of your model!

If you specified a callback, this all happens automatically. Each callback
receives at least 4 parameters: The ``root``, where the data lives, the two
datasets ``data_in``, which was fed into the model and ``data_out``, which was
generated by the model, and the ``config``. You can specify additional keyword
arguments by defining them in the config under
``eval_pipeline/callback_kwargs``.

Should you want to run evaluations on the generated data after it has been
generated, you can run the ``edeval`` command while specifying the path
to the model outputs csv and the callbacks you want to run.

.. code-block:: bash

    edeval -c path/to/model_outputs.csv -cb name1:callback1 name2:callback2

The callbacks must be supplied using ``name:callback`` pairs. Names must be
unique as ``edeval`` will construct a dictionary from these inputs.

If at some point you need to specify new parameters in your config or change
existing ones, you can do so exactly like you would when running the ``edflow``
command. Simply pass the parameters you want to add/change via the commandline
like this:

.. code-block:: bash

    edeval -c path/to/model_outputs.csv -cb name1:callback1 --key1 val1 --key/path/2 val2

.. warning::
    Changing config parameters from the commandline adds some dangers to the
    eval worklow: E.g. you can change parameters which determine the
    construction of the generating dataset, which potentially breaks the
    mapping between inputs and outputs.
"""

import os
import numpy as np
import pandas as pd  # storing model output paths
import yaml  # metadata
from PIL import Image
import inspect
import re

from edflow.data.util import adjust_support
from edflow.util import walk, retrieve, pop_keypath
from edflow.data.dataset import DatasetMixin, CsvDataset, ProcessedDataset
from edflow.project_manager import ProjectManager as P
from edflow.hooks.hook import Hook
from edflow.custom_logging import get_logger


LOADABLE_EXTS = ["png", "npy", "txt"]


class EvalHook(Hook):
    """Stores all outputs in a reusable fashion."""

    def __init__(
        self,
        dataset,
        sub_dir_keys=[],
        labels_key=None,
        callbacks={},
        config=None,
        step_getter=None,
        keypath="step_ops",
    ):
        """
        .. warning::
            To work with ``edeval`` you **must** specify ``config=config`` when
            instantiating the EvalHook.

        Parameters
        ----------
            dataset : DatasetMixin
                The Dataset used for creating the new data.
            sub_dir_keys : list(str)
                Keys found in :attr:`example`, which will
                be used to make a subdirectory for the stored example.
                Subdirectories are made in a nested fashion in the order of the
                list. The keys will be removed from the example dict and not be
                stored explicitly.
            labels_key : str
                All data behind the key found in the :attr:`example`s, will be
                stored in large arrays and later loaded as labels. This should
                be small data types like ``int`` or ``str`` or small ``numpy``
                arrays.
            callbacks : dict(name: str or Callable)
                All callbacks are called at the end of the epoch. Must
                accept root as argument as well as the generating dataset and
                the generated dataset and a config (in that order). Additional
                keyword arguments found at ``eval_pipeline/callback_kwargs``
                will also be passed to the callbacks. You can also leave this
                empty and supply import paths via :attr:`config`.
            config : object, dict
                An object containing metadata. Must be dumpable by
                ``yaml``. Usually the ``edflow`` config.
                You can define callbacks here as well. These must be under
                the keypath ``eval_pipeline/callbacks``. Also you can define
                additional keyword arguments passed to the callbacks as
                described in :attr:`callbacks`.
            step_getter : Callable
                Function which returns the global step as ``int``.
            keypath : str
                Path in result which will be stored.
        """
        self.logger = get_logger(self)

        config_cbs = retrieve(config, "eval_pipeline/callbacks", default={})
        callbacks.update(config_cbs)

        self.cb_names = list(callbacks.keys())
        self.cb_paths = list(callbacks.values())

        self.cbacks = load_callbacks(callbacks)
        self.logger.info("{}".format(self.cbacks))

        self.sdks = sub_dir_keys
        self.lk = labels_key
        self.data_in = dataset

        self.config = config

        self.gs = step_getter
        self.keypath = keypath

    def before_epoch(self, epoch):
        """

        Parameters
        ----------
        epoch :


        Returns
        -------

        """
        self.data_frame = None
        self.root = os.path.join(P.latest_eval, str(self.gs()))
        self.save_root = os.path.join(self.root, "model_outputs")
        os.makedirs(self.root, exist_ok=True)
        os.makedirs(self.save_root, exist_ok=True)

        self.label_arrs = None

    def before_step(self, step, fetches, feeds, batch):
        """Get dataset indices from batch.

        Parameters
        ----------
        step :

        fetches :

        feeds :

        batch :


        Returns
        -------

        """
        self.idxs = np.array(batch["index_"], dtype=int)

    def after_step(self, step, last_results):
        """

        Parameters
        ----------
        step :

        last_results :


        Returns
        -------

        """

        if self.lk is not None:
            label_vals = pop_keypath(last_results, self.lk, default={})
        else:
            label_vals = {}

        if self.label_arrs is None:
            self.label_arrs = {}
            for k in label_vals.keys():
                example = label_vals[k][0]
                ex_shape = list(np.shape(example))
                shape = [len(self.data_in)] + ex_shape
                s = "x".join([str(s) for s in shape])
                dtype = d = example.dtype

                k_ = k.replace("/", "--")
                savepath = os.path.join(
                    self.save_root, "{}-*-{}-*-{}.npy".format(k_, s, d)
                )
                memmap = np.memmap(savepath, shape=tuple(shape), mode="w+", dtype=dtype)
                self.label_arrs[k] = memmap

        idxs = self.idxs  # indices collected before_step

        for k in label_vals.keys():
            # Can the inner loop be made a fancy indexing assign?
            for i, idx in enumerate(idxs):
                self.label_arrs[k][idx] = label_vals[k][i]

        path_dicts = save_output(
            root=self.save_root,
            example=last_results,
            index=idxs,
            sub_dir_keys=self.sdks,
            keypath=self.keypath,
        )

        if self.data_frame is None:
            columns = sorted(path_dicts[list(path_dicts.keys())[0]])
            if len(columns) == 0:
                # No load heavy logs written out
                pass
            else:
                self.data_frame = pd.DataFrame(columns=columns)

        if self.data_frame is not None:
            for idx, path_dict in path_dicts.items():
                self.data_frame.loc[idx] = path_dict

    def at_exception(self, *args, **kwargs):
        """

        Parameters
        ----------
        *args :

        **kwargs :


        Returns
        -------

        """
        if hasattr(self, "root"):
            self.save_csv()

    def after_epoch(self, epoch):
        """Save csv for reuse and then start the evaluation callbacks

        Parameters
        ----------
        epoch :


        Returns
        -------

        """
        self.save_csv()

        data_out = EvalDataFolder(self.root)

        cb_kwargs = retrieve(self.config, "eval_pipeline/callback_kwargs", default={})

        for n, cb in self.cbacks.items():
            cb_name = "CB: {}".format(n)
            cb_name = "{a}\n{c}\n{a}".format(a="=" * len(cb_name), c=cb_name)
            self.logger.info(cb_name)

            kwargs = cb_kwargs.get(n, {})
            cb(self.root, self.data_in, data_out, self.config, **kwargs)

    def save_csv(self):
        """ """
        csv_path = os.path.join(self.root, "model_output.csv")

        if self.data_frame is not None:
            self.data_frame = self.data_frame.sort_index()
            self.data_frame.to_csv(csv_path, index=False)
        else:
            with open(csv_path, "w+") as csv_file:
                csv_file.write("")

        add_meta_data(csv_path, self.config)

        this_script = os.path.dirname(__file__)
        cb_names = self.cb_names
        cb_paths = self.cb_paths

        if cb_names:
            cbs = " ".join("{}:{}".format(k, v) for k, v in zip(cb_names, cb_paths))
        else:
            cbs = "<name>:<your callback>"

        self.logger.info("MODEL_OUPUT_CSV {}".format(csv_path))
        self.logger.info(
            "All data has been produced. You can now also run all"
            + " callbacks using the following command:\n"
            + "edeval -c {} -cb {}".format(csv_path, cbs)
        )


class TemplateEvalHook(EvalHook):
    """EvalHook that disables itself when the eval op returns None."""

    def before_epoch(self, *args, **kwargs):
        self._active = True
        super().before_epoch(*args, **kwargs)

    def before_step(self, *args, **kwargs):
        if self._active:
            super().before_step(*args, **kwargs)

    def after_step(self, step, last_results):
        if retrieve(last_results, self.keypath) is None:
            self._active = False
        if self._active:
            super().after_step(step, last_results)

    def after_epoch(self, *args, **kwargs):
        if self._active:
            super().after_epoch(*args, **kwargs)

    def at_exception(self, *args, **kwargs):
        if self._active:
            super().at_exception(*args, **kwargs)


class EvalDataFolder(DatasetMixin):
    """ """

    def __init__(self, root, show_bar=False):
        er = EvalReader(root)

        if "model_output.csv" not in root:
            csv_path = os.path.join(root, "model_output.csv")
        else:
            csv_path = root
            root = os.path.dirname(root)

        labels = load_labels(os.path.join(root, "model_outputs"))

        # Capture the case that only labels have been written out
        try:
            csv_data = CsvDataset(csv_path, comment="#")
            self.data = ProcessedDataset(csv_data, er)
        except pd.errors.EmptyDataError as e:
            exemplar_labels = labels[sorted(labels.keys())[0]]
            self.data = EmptyDataset(len(exemplar_labels), labels)

        self.data.labels.update(labels)

        self.append_labels = True


class EmptyDataset(DatasetMixin):
    """ """

    def __init__(self, n_ex, labels={}):
        self.len = n_ex
        self.labels = labels

    def get_example(self, idx):
        """

        Parameters
        ----------
        idx :


        Returns
        -------

        """
        return {"content": None}

    def __len__(self):
        return self.len


def load_labels(root):
    """

    Parameters
    ----------
    root :


    Returns
    -------

    """
    regex = re.compile(r".*-\*-.*-\*-.*\.npy")

    files = os.listdir(root)
    label_files = [f for f in files if regex.match(f) is not None]

    labels = {}
    for f in label_files:
        f_ = f.strip(".npy")
        key, shape, dtype = f_.split("-*-")
        shape = tuple([int(s) for s in shape.split("x")])

        path = os.path.join(root, f)

        labels[key] = np.memmap(path, mode="c", shape=shape, dtype=dtype)

    return labels


def save_output(root, example, index, sub_dir_keys=[], keypath="step_ops"):
    """Saves the ouput of some model contained in ``example`` in a reusable
    manner.

    Parameters
    ----------
    root : str
        Storage directory
    example : dict
        name: datum pairs of outputs.
    index : list(int
        dataset index corresponding to example.
    sub_dir_keys : list(str
        Keys found in :attr:`example`, which will be
        used to make a subirectory for the stored example. Subdirectories
        are made in a nested fashion in the order of the list. The keys
        will be removed from the example dict and not be stored.
        Directories are name ``key:val`` to be able to completely recover
        the keys. (Default value = [])

    Returns
    -------
    dict
        Name: path pairs of the saved ouputs.
    dict
        Name: path pairs of the saved ouputs.
        .. warning:: Make sure the values behind the ``sub_dir_keys`` are compatible with
    dict
        Name: path pairs of the saved ouputs.
        .. warning:: Make sure the values behind the ``sub_dir_keys`` are compatible with
        the file system you are saving data on.

    """

    example = retrieve(example, keypath)

    sub_dirs = [""] * len(index)
    for subk in sub_dir_keys:
        sub_vals = _delget(example, subk)
        for i, sub_val in enumerate(sub_vals):
            name = "{}:{}".format(subk, sub_val)
            name = name.replace("/", "--")
            sub_dirs[i] = os.path.join(sub_dirs[i], name)

    roots = [os.path.join(root, sub_dir) for sub_dir in sub_dirs]
    for r in roots:
        os.makedirs(r, exist_ok=True)

    roots += [root]

    path_dicts = {}
    for i, [idx, root] in enumerate(zip(index, roots)):
        path_dict = {}
        for n, e in example.items():
            savename = "{}_{:0>6d}.{{}}".format(n, idx)
            path = os.path.join(root, savename)

            path = save_example(path, e[i])

            path_dict[n + "_path"] = path
        path_dicts[idx] = path_dict

    return path_dicts


def add_meta_data(path_to_csv, metadata):
    """Prepends kwargs of interest to a csv file as comments (`#`)

    Parameters
    ----------
    path_to_csv :

    metadata :


    Returns
    -------

    """

    meta_string = yaml.dump(metadata)

    commented_string = ""
    for line in meta_string.split("\n"):
        line = "# {}\n".format(line)
        commented_string += line

    with open(path_to_csv, "r+") as csv_file:
        content = csv_file.read()

    content = commented_string + content

    with open(path_to_csv, "w+") as csv_file:
        csv_file.write(content)


def read_meta_data(path_to_csv):
    """This functions assumes that the first lines of the csv are the commented
    output of a ``yaml.dump()`` call and loads its contents for further use.

    Parameters
    ----------
    path_to_csv :


    Returns
    -------

    """

    with open(path_to_csv, "r") as csv_file:
        yaml_string = ""
        for line in csv_file.readlines():
            if "# " in line:
                yaml_string += line[2:] + "\n"
            else:
                break

    meta_data = yaml.full_load(yaml_string)

    return meta_data


def _delget(d, k):
    """

    Parameters
    ----------
    d :

    k :


    Returns
    -------

    """
    v = d[k]
    del d[k]
    return v


def save_example(savepath, datum):
    """
    Manages the writing process of a single datum: (1) Determine type,
    (2) Choose saver, (3) save.

    Parameters
    ----------
    savepath : str
        Where to save. Must end with `.{}` to put in the
        file ending via `.format()`.
    datum : object
        Some python object to save.

    Returns
    -------

    """

    saver, ending = determine_saver(datum)

    savepath = savepath.format(ending)

    saver(savepath, datum)

    return savepath


def determine_saver(py_obj):
    """Applies some heuristics to save an object.

    Parameters
    ----------
    py_obj :


    Returns
    -------

    """

    if isinstance(py_obj, np.ndarray):
        if isimage(py_obj):
            return image_saver, "png"
        else:
            return np_saver, "npy"

    elif isinstance(py_obj, str):
        return txt_saver, "txt"

    else:
        raise NotImplementedError(
            "There currently is not saver heuristic " + "for {}".format(type(py_obj))
        )


def load_by_heuristic(path):
    """Chooses a loader based on the file ending.

    Parameters
    ----------
    path :


    Returns
    -------

    """

    name, ext = os.path.splitext(path)

    if ext == ".png":
        return image_loader(path)
    elif ext == ".npy":
        return np_loader(path)
    elif ext == ".txt":
        return txt_loader(path)
    else:
        raise ValueError("Cannot load file with extension `{}` at {}".format(ext, path))


def decompose_name(name):
    """

    Parameters
    ----------
    name :


    Returns
    -------

    """
    try:
        splits = name.split("_")
        rest = splits[-1]
        datum_name = "_".join(splits[:-1])
        index, ending = rest.split(".")

        return int(index), datum_name, ending
    except Exception as e:
        print("Faulty name:", name)
        raise e


def is_loadable(filename):
    """

    Parameters
    ----------
    filename :


    Returns
    -------

    """
    if "." in filename:
        name, ext = filename.split(".")
        if ext not in LOADABLE_EXTS:
            return False
        elif name.count("_") != 1:
            return False
        else:
            return True
    else:
        return False


class EvalLabeler(object):
    """ """

    def __init__(self, root):
        self.root = root

        self.visited = []

    def __call__(self, path):
        """Adds the labels ``paths``, ``kind``, ``index_``, ``datum_root``"""

        ret_dict = {}

        rel = os.path.relpath(path, self.root)
        folder_structure, filename = os.path.split(rel)

        if not is_loadable(filename):
            return None

        # Do that first, the pass if index already in there.
        # Now get all the files with the same index
        index, datum_name, ending = decompose_name(filename)

        if index not in self.visited:
            self.visited += [index]
            # Get the sbfolder key val pairs
            for kv in folder_structure.split("/"):
                key, val = kv.split(":")
                val = val.replace("--", "/")
                ret_dict[key] = val

            # get all files with this index
            # We know all files must be in the folder, as we must assume, that
            # index_ is a unique key. Otherwise this whole system does not
            # work.

            all_files = os.listdir(os.path.join(self.root, folder_structure))

            def idx_filter(fname):
                """

                Parameters
                ----------
                fname :


                Returns
                -------

                """
                n, e = os.path.splitext(fname)
                if "." in e:
                    has_nice_ending = e[1:] in LOADABLE_EXTS
                else:
                    return False
                return "{:0>6d}".format(index) in fname and has_nice_ending

            of_interest = filter(idx_filter, all_files)

            # Remember the filenames -> Not really neccessary, but makes
            # reading code cleaner (hopefully).
            for filename in of_interest:
                path = os.path.join(self.root, folder_structure, filename)
                _, datum_name, ending = decompose_name(filename)
                ret_dict["{}_{}".format(datum_name, "path")] = path

            ret_dict["datum_root"] = os.path.join(self.root, folder_structure)

            ret_dict["save_index_"] = index

            return ret_dict


class EvalReader(object):
    """ """

    def __init__(self, root):
        self.root = root

    def __call__(self, **kwargs):
        """Works only with non legacy DataFolder!"""

        ret_dict = {}

        if "file_path_" in kwargs:
            del kwargs["file_path_"]

        path_keys = [f for f in list(kwargs.keys()) if "path" in f]

        for k in path_keys:
            path = kwargs[k]
            name = "_".join(os.path.basename(k).split("_")[:-1])

            ret_dict[name] = load_by_heuristic(path)

        return ret_dict


def isimage(np_arr):
    """

    Parameters
    ----------
    np_arr :


    Returns
    -------

    """
    shape = np_arr.shape
    return len(shape) == 3 and shape[-1] in [1, 3, 4]


def image_saver(savepath, image):
    """

    Parameters
    ----------
    savepath :

    image :


    Returns
    -------

    """
    im_adjust = adjust_support(image, "0->255", clip=True)

    modes = {1: "L", 3: "RGB", 4: "RGBA"}
    mode = modes[im_adjust.shape[-1]]
    if mode == "L":
        im_adjust = np.squeeze(im_adjust, -1)

    im = Image.fromarray(im_adjust, mode)

    im.save(savepath)


def image_loader(path):
    """

    Parameters
    ----------
    path :


    Returns
    -------

    """
    im = np.array(Image.open(path))
    return im


def np_saver(savepath, np_arr):
    """

    Parameters
    ----------
    savepath :

    np_arr :


    Returns
    -------

    """
    np.save(savepath, np_arr)


def np_loader(path):
    """

    Parameters
    ----------
    path :


    Returns
    -------

    """
    return np.load(path)


def txt_saver(savepath, string):
    """

    Parameters
    ----------
    savepath :

    string :


    Returns
    -------

    """
    with open(savepath, "a+") as f:
        f.write(string + "\n")


def txt_loader(path):
    """

    Parameters
    ----------
    path :


    Returns
    -------

    """
    with open(path, "r") as f:
        data = f.read()

    return data


def standalone_eval_csv_file(
    path_to_csv, callbacks, additional_kwargs={}, other_config=None
):
    """Runs all given callbacks on the data in the :class:`EvalDataFolder`
    constructed from the given csv.abs

    Parameters
    ----------
    path_to_csv : str
        Path to the csv file.
    callbacks : dict(name: str or Callable)
        Import commands used to construct the functions applied to the Data
        extracted from :attr:`path_to_csv`.
    additional_kwargs : dict
        Keypath-value pairs added to the config, which is extracted from
        the ``model_outputs.csv``. These will overwrite parameters in the
        original config extracted from the csv.
    other_config : str
        Path to additional config used to update the existing one as taken from
        the ``model_outputs.csv`` . Cannot overwrite the dataset. Only used for
        callbacks. Parameters in this other config will overwrite the
        parameters in the original config and those of the commandline
        arguments.

    Returns
    -------
    outputs: dict
        The collected outputs of the callbacks.
    """

    from edflow.main import get_implementations_from_config
    from edflow.config import update_config
    import yaml

    if other_config is not None:
        with open(other_config, "r") as f:
            other_config = yaml.full_load(f)
    else:
        other_config = {}

    out_data = EvalDataFolder(path_to_csv)

    config = read_meta_data(path_to_csv)

    dataset_str = config["dataset"]
    impl = get_implementations_from_config(config, ["dataset"])
    in_data = impl["dataset"](config)

    update_config(config, additional_kwargs)
    config.update(other_config)

    config_callbacks, callback_kwargs = config2cbdict(config)
    callbacks.update(config_callbacks)

    callbacks = load_callbacks(callbacks)

    root = os.path.dirname(path_to_csv)

    outputs = apply_callbacks(
        callbacks, root, in_data, out_data, config, callback_kwargs
    )

    return outputs


def load_callbacks(callbacks):
    """Loads all callbacks, i.e. if the callback is given as str, will load the
    module behind the import path, otherwise will do nothing.
    """
    import importlib
    import sys

    sys.path.append(os.getcwd())  # convenience: load implementations from cwd

    for name, cb in callbacks.items():
        if isinstance(cb, str):
            module = ".".join(cb.split(".")[:-1])
            module = importlib.import_module(module)

            cb = getattr(module, cb.split(".")[-1])

            callbacks[name] = cb

    return callbacks


def apply_callbacks(callbacks, root, in_data, out_data, config, callback_kwargs={}):
    """Runs all given callbacks on the datasets ``in_data`` and ``out_data``.

    Parameters
    ----------
    callbacks : dict(name: Callable)
        List of all callbacks to apply. All callbacks must accept at least the
        signitatue ``callback(root, data_in, data_out, config)``. If supplied
        via the config, additional keyword arguments are passed to the
        callback. These are expected under the keypath
        ``eval_pipeline/callback_kwargs``.
    in_data : DatasetMixin
        Dataset used to generate the content in ``out_data``.
    out_data : DatasetMixin
        Generated data. Example i is expected to be generated using
        ``in_data[i]``.
    config : dict
        edflow config dictionary.
    callback_kwargs : dict
        Keyword Arguments for the callbacks.

    Returns
    -------
    outputs : dict(name: callback output)
        All results generated by the callbacks at the corresponding key.
    """

    outputs = {}
    for name, cb in callbacks.items():
        kwargs = callback_kwargs.get(name, {})
        outputs[name] = cb(root, in_data, out_data, config, **kwargs)

    return outputs


def cbargs2cbdict(arglist):
    """Turns a list of ``name:callback`` into a dict ``{name: callback}``"""

    out = {}
    for arg in arglist:
        splits = arg.split(":")
        if len(splits) != 2:
            raise ValueError(
                "Callbacks must be supplied via the commandline "
                "using `name:import_path` pairs."
            )
        name, cb = splits
        out[name] = cb

    return out


def config2cbdict(config):
    """Extracts the callbacks inside a config and returns them as dict.
    Callbacks must be defined at ``eval_pipeline/callback_kwargs``.
    
    Parameters
    ----------
    config : dict
        A config dictionary. 

    Returns
    -------
    callbacks : dict
        All name:callback pairs as ``dict`` ``{name: callback}``
    """

    callbacks = retrieve(config, "eval_pipeline/callbacks", default={})
    kwargs = retrieve(config, "eval_pipeline/callback_kwargs", default={})

    return callbacks, kwargs


def main():
    import argparse
    from edflow.config import parse_unknown_args

    import sys

    sys.path.append(os.getcwd())  # convenience: load implementations from cwd

    A = argparse.ArgumentParser(
        description="""
Use edeval for running callbacks on data generated using the
``edflow.eval_pipeline.eval_pipeline.EvalHook``. Once the data is created all
you have to do is pass the ``csv``-file created by the hook. It specifies all
the relevant information: Which dataset was used to create the data, along with
all config parameters and where all generated samples live.

Callbacks will be evaluated in the order they have been passed to this
function. They must be supplied in `name:callback` pairs.

For more documentation take a look at ``edflow/eval_pipeline/eval_pipeline.py``
"""
    )

    A.add_argument(
        "-c",
        "--csv",
        default="model_output.csv",
        type=str,
        help="path to a csv-file created by the EvalHook containing"
        " samples generated by a model.",
    )
    A.add_argument(
        "-cb",
        "--callback",
        type=str,
        nargs="*",
        help="Import string to the callback functions used for the "
        "standalone evaluation.",
    )
    A.add_argument(
        "-cf",
        "--other_config",
        type=str,
        default=None,
        help="Other config, which can be used to e.g. update eval_pipeline related "
        "parameters, but also others.",
    )

    args, unknown = A.parse_known_args()
    additional_kwargs = parse_unknown_args(unknown)

    callbacks = cbargs2cbdict(args.callback)

    standalone_eval_csv_file(args.csv, callbacks, additional_kwargs, args.other_config)


if __name__ == "__main__":
    main()
