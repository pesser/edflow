#!/usr/bin/env python3

import os

import sys  # noqa


sys.path.append(os.getcwd())  # convenience: load implementations from cwd

pytorch_mp = os.environ.get("USE_PYTORCH_MP", "False") == "True"
if not pytorch_mp:
    import multiprocessing as mp

    # mp = _mp.set_start_method('spawn')
else:
    print("Using pytorch mp")
    import torch.multiprocessing as mp


import argparse  # noqa
import yaml  # noqa

from edflow.main import train, test  # noqa
from edflow.custom_logging import init_project, use_project, get_logger  # noqa
from edflow.custom_logging import set_global_stdout_level  # noqa
from edflow.hooks.checkpoint_hooks.common import get_latest_checkpoint  # noqa


def update_config(config, options):
    if options is not None:
        for option in options:
            config.update(yaml.load(option))
    # single format substitution, does not support nested structures
    for k, v in config.items():
        if isinstance(v, str):
            config[k] = v.format(**config)


def main(opt):
    # Project manager
    if opt.project is not None:
        P = use_project(opt.project, postfix=opt.name)
    else:
        assert opt.train is not None
        # Get base or default parameters
        base_config = {}
        if opt.base is not None:
            for base in opt.base:
                print(base)
                with open(base) as f:
                    base_config.update(yaml.load(f))
        print(base_config)
        # get path to implementation
        with open(opt.train) as f:
            config = base_config
            config.update(yaml.load(f))
            update_config(config, opt.option)
            impl = config["model"]
            name = config.get("experiment_name", None)
        # if it looks like a package path, take its root as the code dir
        # otherwise take cwd
        if "code_root" in config:
            code_root = config["code_root"]
        else:
            path = impl.split(".")
            if len(path) > 0:
                code_root = path[0]
            else:
                code_root = "."

        if opt.name is not None:
            # command line takes precedence over "experiment_name" from
            # config
            name = opt.name
        P = init_project("logs", code_root=code_root, postfix=name)

    # Logger
    set_global_stdout_level(opt.log_level)
    logger = get_logger("main")
    logger.info(opt)
    logger.info(P)

    # Processes
    processes = list()

    # Error Communication between processes
    JQ = mp.Queue()

    # Training
    if opt.train:
        if opt.checkpoint is not None:
            checkpoint = opt.checkpoint
        elif opt.project is not None:
            checkpoint = get_latest_checkpoint(P.checkpoints)
        else:
            checkpoint = None

        base_config = {}
        if opt.base is not None:
            for base in opt.base:
                print(base)
                with open(base) as f:
                    base_config.update(yaml.load(f))
        print(base_config)
        # get path to implementation
        with open(opt.train) as f:
            config = base_config
            config.update(yaml.load(f))
            update_config(config, opt.option)

        logger.info("Training config: {}".format(opt.train))
        logger.info(yaml.dump(config))

        train_process = mp.Process(
            target=train,
            args=((config, P.train, checkpoint, opt.retrain), JQ, len(processes)),
        )
        processes.append(train_process)

    # Evaluation
    opt.eval = opt.eval or list()
    for eval_idx, eval_config in enumerate(opt.eval):
        base_config = {}
        if opt.base is not None:
            for base in opt.base:
                with open(base) as f:
                    base_config.update(yaml.load(f))
        # get path to implementation
        with open(eval_config) as f:
            config = base_config
            config.update(yaml.load(f))
            update_config(config, opt.option)
        logger.info("Evaluation config: {}".format(eval_config))
        logger.info(yaml.dump(config))
        nogpu = len(processes) > 0 or opt.nogpu
        bar_position = len(processes) + eval_idx
        test_process = mp.Process(
            target=test,
            args=((config, P.latest_eval, nogpu, bar_position), JQ, len(processes)),
        )
        processes.append(test_process)

    # Take off
    try:
        for p in processes:
            p.start()
        logger.info("Started {} process(es).".format(len(processes)))

        done_count = 0
        while True:
            pidx, exc_or_done, trace = JQ.get()
            if isinstance(exc_or_done, Exception):
                logger.warn("Exception in process {}:".format(pidx))
                logger.warn(trace)
                raise exc_or_done
            elif exc_or_done == "Done":
                logger.info("Process {} is done".format(pidx))
                done_count += 1
            else:
                raise Exception("Unknown element on queue.")

            if done_count >= len(processes):
                break

    except (Exception, KeyboardInterrupt) as e:
        logger.info("Terminating all processes")
        for p in processes:
            p.terminate()

        raise e
    finally:
        # Landing
        for p in processes:
            p.join()
        logger.info("Finished")


if __name__ == "__main__":
    default_log_dir = os.path.join(os.getcwd(), "log")

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-n", "--name", metavar="description", help="postfix of log directory."
    )
    parser.add_argument(
        "-b",
        "--base",
        nargs="*",
        metavar="base_config.yaml",
        help="Path to base config. Any parameter in here is overwritten by "
        "the train of eval config. Useful e.g. for model parameters, which"
        " stay constant between trainings and evaluations.",
        default=None,
    )
    parser.add_argument(
        "-t", "--train", metavar="config.yaml", help="path to training config"
    )
    parser.add_argument(
        "-e",
        "--eval",
        nargs="*",
        metavar="config.yaml",
        help="path to evaluation configs",
    )
    parser.add_argument("-p", "--project", help="path to existing project")
    parser.add_argument("-c", "--checkpoint", help="path to existing checkpoint")
    parser.add_argument(
        "-r", "--retrain", action="store_true", help="reset global step"
    )
    parser.add_argument(
        "--nogpu", action="store_true", help="disable gpu for tensorflow"
    )
    parser.add_argument(
        "--option",
        "-o",
        action="append",
        help="additional key: value options to update all config with",
    )
    parser.add_argument(
        "-log",
        "--log-level",
        metavar="LEVEL",
        type=str,
        choices=["info", "debug", "critical"],
        default="info",
        help="Set the std-out logging level.",
    )
    opt = parser.parse_args()
    main(opt)
