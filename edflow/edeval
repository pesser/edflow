#!/usr/bin/env python3

import argparse
from edflow.eval.pipeline import standalone_eval_csv_file

A = argparse.ArgumentParser(
    description="""
Use edeval for running callbacks on data generated using the
``edflow.eval_pipeline.eval_pipeline.EvalHook``. Once the data is created all
you have to do is pass the ``csv``-file created by the hook. It specifies all
the relevant information: Which dataset was used to create the data, along with
all config parameters and where all generated samples live.

Callbacks will be evaluated in the order they have been passed to this
function.

For more documentation take a look at ``edflow/eval_pipeline/eval_pipeline.py``
"""
)

A.add_argument(
    "-c",
    "--csv",
    default="model_output.csv",
    type=str,
    help="path to a csv-file created by the EvalHook containing"
    " samples generated by a model.",
)
A.add_argument(
    "-cb",
    "--callback",
    type=str,
    nargs="*",
    help="Import string to the callback functions used for the "
    "standalone evaluation.",
)

args = A.parse_args()

standalone_eval_csv_file(args.csv, args.callback)
